{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyBmlZZBUYFNa2iwqOn3yNJsV_KlCbvjAN8\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Configurações do Modelo\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.7,\n",
        "}\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")\n",
        "\n",
        "# Funções de Diálogo\n",
        "def obter_nome_cliente():\n",
        "  nome = input(\"Olá! Por favor, me diga seu nome: \")\n",
        "  return nome\n",
        "\n",
        "def identificar_intencao(mensagem):\n",
        "  # Lógica para identificar a intenção do usuário\n",
        "  # Substitua por sua implementação de NLU (Dialogflow, Rasa, etc.)\n",
        "  if \"pedido\" in mensagem:\n",
        "    return \"verificar_pedido\"\n",
        "  elif \"produto\" in mensagem:\n",
        "    return \"informacoes_produto\"\n",
        "  else:\n",
        "    return \"duvida_geral\"\n",
        "\n",
        "def processar_verificar_pedido(mensagem, nome_cliente):\n",
        "  # Lógica para extrair o número do pedido da mensagem\n",
        "  # Substitua por sua implementação de extração de entidades\n",
        "  numero_pedido = \"123456\"  # Exemplo\n",
        "  # Lógica para consultar API externa e obter o status do pedido\n",
        "  status_pedido = \"Em processamento\"  # Exemplo\n",
        "  resposta = f\"{nome_cliente}, o status do seu pedido {numero_pedido} é: {status_pedido}\"\n",
        "  return resposta\n",
        "\n",
        "def processar_informacoes_produto(mensagem, nome_cliente):\n",
        "  # Lógica para extrair o nome do produto da mensagem\n",
        "  # Substitua por sua implementação de extração de entidades\n",
        "  nome_produto = \"Camiseta Azul\"  # Exemplo\n",
        "  # Lógica para consultar base de conhecimento ou API externa\n",
        "  # e obter informações sobre o produto\n",
        "  descricao_produto = \"Camiseta azul, 100% algodão, tamanho M\"  # Exemplo\n",
        "  resposta = f\"{nome_cliente}, aqui estão as informações sobre o produto {nome_produto}: {descricao_produto}\"\n",
        "  return resposta\n",
        "\n",
        "def processar_duvida_geral(mensagem, nome_cliente):\n",
        "  # Utiliza o Gemini para gerar uma resposta para a dúvida geral\n",
        "  resposta = model.generate_content(f\"Cliente: {mensagem}\").text\n",
        "  return resposta\n",
        "\n",
        "def obter_feedback():\n",
        "  feedback = input(\"Você está satisfeito(a) com o atendimento? (sim/não): \")\n",
        "  return feedback\n",
        "\n",
        "# Loop Principal\n",
        "nome_cliente = obter_nome_cliente()\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "while True:\n",
        "  mensagem = input(f\"{nome_cliente}: \")\n",
        "  if mensagem.lower() == \"fim\":\n",
        "    break\n",
        "\n",
        "  intencao = identificar_intencao(mensagem)\n",
        "\n",
        "  if intencao == \"verificar_pedido\":\n",
        "    resposta = processar_verificar_pedido(mensagem, nome_cliente)\n",
        "  elif intencao == \"informacoes_produto\":\n",
        "    resposta = processar_informacoes_produto(mensagem, nome_cliente)\n",
        "  else:\n",
        "    resposta = processar_duvida_geral(mensagem, nome_cliente)\n",
        "\n",
        "  print(f\"Chatbot: {resposta}\")\n",
        "\n",
        "feedback = obter_feedback()\n",
        "print(f\"Chatbot: Obrigado pelo feedback, {nome_cliente}. Até logo!\")"
      ],
      "metadata": {
        "id": "xqLELWbDbemU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}